\chapter{Introduction}

Automatic data processing and analysis is nowadays essential in many disciplines in science and
beyond. The unmatched availability of computational resources experienced in present times has
stimulated the stablishment of new disciplines that strongly depend on analysis of massive amounts
of data, for which humans are no longer suitable, which makes automatic processing by computational
methods paramount.

A clear example of this is found in biology. Methods such as \emph{genome-wide association
studies}, \emph{high-content screening}, or \emph{gene expression profiling} are relatively new, and
rely on the analysis of huge amounts of data that would not have been possible in the past.

Machine learning is a very popular approach to automatic data processing. Machine learning is a
branch of artificial intelligence that allows to describe and detect patterns in groups of objects
that can be later used for recognition of other objects with similar characteristics.

Machine learning methods that infer such patterns by studying a set of labeled (training) data are
known as {\bf \emph{supervised} machine learning algorithms}, as opposite to \emph{unsupervised} machine
learning methods, which are not exposed to any training information. 
Supervised machine learning techniques are the most widely used.

% Talk about learning and prediction 

However, since many such methods exist, it is usually not obvious which one to use to address a specific
problem, i.e., which method recognizes patterns that serve as a good \emph{model} of the data.
Furthermore, each different method usually exposes configuration options that modify its behavior and
may enhance or harm its predictive capacity.

\subsubsection{Supervised machine learning approaches}

	Supervised machine learning (SML) methods address two families of problems: classification and
	regression. In the {\bf classification} problem, objects belong to a class from a given set, and
	the method should infer rules to assign new objects to their corresponding class. The {\bf
	regression} problem locates objects in a certain space, and should correctly predict the
	location of new objects.  % position?

\subsubsection{Model selection}
	Different SML methods use different strategies to learn the patterns
	that they use for prediction. Some of them make assumptions on the structure of the data, and
	do not give accurate predictions when such assumptions are violated. The choice of the method to
	use is bound to the structure of the data that they are to predict.

	The model selection problem is the evaluation of a series of candidate models in order to select
	the best one, according to some optimality criterion. The underlying rule learned by a SML
	algorithm, and used by it to map objects to values, is considered as a model of the object
	space. To select a SML model then means to evaluate a group of SML algorithms in order to choose
	the one that best maps objects to their target values.

\subsubsection{Hyperparameter optimization}
	Specific configuration options for each SML method control its internal behavior,
	and can affect the learning of patterns to use for prediction. Finding the right combination of
	configuration options (\emph{hyperparameters}) might be as critical to the prediction as
	selecting the right machine learning method.

	An exhaustive evaluation of all possible hyperparameter combinations is not practical, and it is
	not even possible when any of the hyperparameters adopts values from a continuous range.
	Numerical optimization approaches can be used to systematically suggest new candidate values
	expected to improve the prediction of the SML algorithm.
